import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

housing = fetch_california_housing()

df = pd.DataFrame(housing.data, columns=housing.feature_names)
df["Target"] = housing.target

print("âœ… Dataset loaded successfully!")
print(df.head())

# Step 4: Choose features (independent variable) and target (dependent variable)
# We'll predict "Median House Value (Target)" using "Average Number of Rooms"
X = df[["AveRooms"]]   # Feature (independent variable)
y = df["Target"]       # Target (dependent variable)

# Step 5: Split dataset into Training and Testing data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Step 6: Create and train the Linear Regression model
model = LinearRegression()
model.fit(X_train, y_train)

# Step 7: Make predictions
y_pred = model.predict(X_test)

# Step 8: Evaluate model performance
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print("\nðŸ“Š Model Performance:")
print(f"Mean Squared Error (MSE): {mse:.4f}")
print(f"RÂ² Score: {r2:.4f}")

# Step 9: Display learned slope and intercept
print("\nðŸ§© Model Parameters:")
print("Slope (m):", model.coef_[0])
print("Intercept (b):", model.intercept_)

# Step 10: Visualization
plt.figure(figsize=(8,5))
plt.scatter(X_test, y_test, color='blue', alpha=0.4, label="Actual Data")
plt.plot(X_test, y_pred, color='red', linewidth=2, label="Predicted Line")
plt.xlabel("Average Number of Rooms")
plt.ylabel("Median House Value")
plt.title("Linear Regression â€“ California Housing")
plt.legend()
plt.grid(True)
plt.show()
